# -*- coding: utf-8 -*-
"""TFM_ASANZC_v1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WUZltPu5sD0EXIZZlt-8j_OqKEPIV4ZE

# Cálculo del nivel de enfoque sobre zonas de una imagen

### Antonio Sanz 

En este notebook entreno un red convolucional sobre el dataset de imágenes cifar-10. Esta dataset contiene 50K imágenes, todas ellas con un nivel de contraste alto que consideraremos óptimo en este caso. Para poder entrenar nuestra red con imagenes desenfocadas y borrosas, he aplicado un filtro Gaussiano con diferentes tamaños de Kernel para obtener 6 enfoques diferentes sobre cada imagen. Los directorios de train y test tienen esta estructura:

- /train
 - /blur3
 - /blur9
 - /blur15
 - /focus
- /test
 - /blur3
 - /blur9
 - /blur15
 - /focus
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x

import tensorflow as tf
import subprocess
import os
import numpy as np
import cv2 as cv

import matplotlib.pyplot as plt
from keras import optimizers
from keras.models import load_model
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
from keras.layers import Flatten
from keras.layers import Input

from keras.constraints import maxnorm
from keras.layers.convolutional import Convolution2D
from keras.layers.convolutional import MaxPooling2D
from keras.preprocessing.image import ImageDataGenerator

from keras.models import load_model

# %matplotlib inline

from google.colab import drive

drivedir = '/content/gdrive'

drive.mount(drivedir)

print('Google Drive mount completed')

#check correct mount of drive directory
!df -h

! git clone https://github.com/antonio490/Autofocus.git

# DIRECTORIOS

DIR_GDRIVE = drivedir + '/My Drive/TFM/modelos/' 
DIR_GDRIVE_PLOTS = drivedir + '/My Drive/TFM/plots/' 


prac_dir = '/content/Autofocus/out/' # Dataset con 2 clases
#prac_dir = '/content/Autofocus/out_multiclass/' # Dataset con 4 clases


train_dir = prac_dir + 'train' # Directorio datos train
test_dir = prac_dir + 'test' # Directorio datos test

os.chdir(prac_dir) # Nos desplazamos al directorio padre

# HIPERPARAMETROS 

BATCH_SIZE = 64
IMAGE_RESIZE = 32

# AUMENTAMOS CONJUNTO DE DATOS DE ENTRENAMIENTO

train_datagen = ImageDataGenerator(
    rescale=1./255,
    horizontal_flip = True,
    )

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(IMAGE_RESIZE,IMAGE_RESIZE),
        batch_size=BATCH_SIZE,
        #color_mode="grayscale",
        class_mode='categorical'
        )

validation_generator = test_datagen.flow_from_directory(
        test_dir,
        target_size=(IMAGE_RESIZE,IMAGE_RESIZE),
        batch_size=BATCH_SIZE,
        #color_mode="grayscale",
        class_mode='categorical'
        )

# HIPERPARAMETROS 

L_RATE  = 0.01
EPOCHS = 30
TRAIN_SAMPLES = train_generator.n 
VAL_SAMPLES = validation_generator.n 
NUM_CLASSES = train_generator.num_classes

STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size
STEP_SIZE_VAL = validation_generator.n//validation_generator.batch_size

# CALLBACKS

if NUM_CLASSES <= 2:
	ACCURACY_THRESHOLD = 0.98
elif NUM_CLASSES > 2:
	ACCURACY_THRESHOLD = 0.96

class MinAccuracy(tf.keras.callbacks.Callback):
	def on_epoch_end(self, epoch, logs={}):
		if(logs.get('accuracy') > ACCURACY_THRESHOLD and epoch > 15):
			print("\nSe ha alcanzado un precisión del %2.2f%% , paramos entrenamiento!!" %(ACCURACY_THRESHOLD*100))
			self.model.stop_training = True

# Stop training when a monitored quantity has stopped improving.
# patience: number of epochs that produced the monitored quantity with no improvement after which training will be stopped.

early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, verbose=1, min_delta=1e-4)  

# Reduce learning rate when a metric has stopped improving.
# This callback monitors a quantity and if no improvement is seen for a 'patience' number of epochs, the learning rate is reduced.

reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_delta=1e-4)  


# Instanciamos objeto MinAccuracy
min_accuracy = MinAccuracy()

callbacks_list = [reduce_lr, min_accuracy] #min_accuracy, early_stop, reduce_lr]

# ARQUITECTURA RED CONVOLUCIONAL

def Net():

  modelo = tf.keras.Sequential()
  modelo.add(tf.keras.layers.Convolution2D(10, 3, input_shape=(IMAGE_RESIZE, IMAGE_RESIZE, 3), padding='same', strides=(1,1), activation='relu'))
  modelo.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))
  modelo.add(tf.keras.layers.Convolution2D(30, 5, strides=(1,1), activation='relu'))
  modelo.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))
  modelo.add(tf.keras.layers.Convolution2D(64, 4, strides=(1,1), activation='relu'))  
  modelo.add(tf.keras.layers.Dropout(0.8))

  modelo.add(tf.keras.layers.Flatten())
  modelo.add(tf.keras.layers.Dense(64, activation='relu')) 
  modelo.add(tf.keras.layers.Dense(2, activation='relu')) 

  modelo.add(tf.keras.layers.Dense(NUM_CLASSES, activation='softmax'))

  modelo.summary()
  return modelo

modelo = Net()

# OPTIMIZADORES

#rms = tf.keras.optimizers.RMSprop(learning_rate=L_RATE, rho=0.9)
#adam = tf.keras.optimizers.Adam(learning_rate=L_RATE, beta_1=0.9, beta_2=0.999, amsgrad=False)
#adamax = tf.keras.optimizers.Adamax(lr=L_RATE, beta_1=0.9, beta_2=0.999)
sgd = tf.keras.optimizers.SGD(lr=L_RATE, decay=0.0005, momentum=0.9)

#modelo.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])
modelo.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])

# ENTRENAMIENTO MODELO 

m = modelo.fit(
          train_generator,
          steps_per_epoch = STEP_SIZE_TRAIN, 
          epochs = EPOCHS,
          validation_data = validation_generator,
          callbacks = callbacks_list,
          validation_steps = STEP_SIZE_VAL
          )

# Commented out IPython magic to ensure Python compatibility.
# VISUALIZACIONES

from pylab import *
# %matplotlib inline

_, ax1 = subplots()
ax2 = ax1.twinx()
ax1.plot(m.history['loss'], 'b')
ax2.plot(m.history['val_accuracy'], 'r')
ax1.set_xlabel('iteration')
ax1.set_ylabel('train loss')
ax2.set_ylabel('test accuracy')
ax2.set_xlabel('Test accuracy: {:.2f}'.format(m.history['val_accuracy'][-1]))

plt.savefig(DIR_GDRIVE_PLOTS + "modelo_" + str(NUM_CLASSES) + "_" + str(EPOCHS) + "_Net_1.png")

plt.figure()
plt.ylabel("Loss (training and validation)")
plt.xlabel("Training Steps")
plt.ylim([0,2])
plt.plot(m.history["loss"], 'b')
plt.plot(m.history["val_loss"], 'r')

plt.savefig(DIR_GDRIVE_PLOTS + "modelo_" + str(NUM_CLASSES) + "_" + str(EPOCHS) + "_Net_2.png")

plt.figure()
plt.ylabel("Accuracy (training and validation)")
plt.xlabel("Training Steps")
plt.ylim([0,1])
plt.plot(m.history["accuracy"], 'b')
plt.plot(m.history["val_accuracy"], 'r')

plt.savefig(DIR_GDRIVE_PLOTS + "modelo_" + str(NUM_CLASSES) + "_" + str(EPOCHS) + "_Net_3.png")

# ALMACENAMOS LOS PESOS DE NUESTRO MODELO ENTRENADO

modelo.save(DIR_GDRIVE + "modelo_" + str(NUM_CLASSES) + "_" + str(EPOCHS) + "_Net") 
print("Saved model to disk")

modelo.save_weights(DIR_GDRIVE + "modelo_" + str(NUM_CLASSES) + "_" + str(EPOCHS) + "_Net_weights.h5")
print("Saved model weights to disk")

def load_trained_model(path, flag):

  if flag:
    m = pNet()
    m.load_weights(path + "_weights.h5")
  else:
    m = tf.keras.models.load_model(path)
  return m

# VISUALIZACION SECCIONES IMAGENES 32x32

def showGridImage(img_array):
  plt.figure(figsize=(8,8))
  plt.subplots_adjust(hspace=0.2)
  for n in range(sub_images**2):
    plt.subplot(sub_images, sub_images, n+1)
    plt.imshow(img_array[n], cmap="gray")
    plt.axis('off')

# VISUALIZACION PREDICCION IMAGENES 32x32

def predictBlur(modelo, img_array):
  testGEN.reset()
  predictions = modelo.predict(testGEN, steps=testGEN.n//testGEN.batch_size, verbose=1)
  image_batch = next(testGEN)

  plt.figure(figsize=(5,5))
  plt.subplots_adjust(hspace=0.3)

  for k in range(sub_images**2):
    image = image_batch[k]
    pred = predictions[k]
    the_pred = np.argmax(pred)
    predicted = class_names[the_pred]
    plt.subplot(sub_images, sub_images, k+1)
    plt.imshow(img_array[k], cmap="gray")
    color = "green" if predicted == "Focus" else "red"
    plt.title(predicted.title(), color=color)
    plt.axis('off')
    plt.savefig(DIR_GDRIVE_PLOTS + "model_predict_" + str(sub_images) + ".png")

#m = load_trained_model(DIR_GDRIVE + "modelo_" + str(BATCH_SIZE) + "_" + str(EPOCHS) + "_Net", False)

class_names = sorted(train_generator.class_indices.items(), key=lambda pair:pair[1])
class_names = np.array([key.title() for key, value in class_names])
print(class_names)

SIZE = 128

#img = cv.imread(DIR_GDRIVE + "photos/IMG_1591717005.png") # Blur
#img = cv.imread(DIR_GDRIVE + "photos/IMG_1591716996.png") # Focus

#img = cv.imread(DIR_GDRIVE + "photos/IMG_1591717516.png") # Blur

# 128
img = cv.imread(DIR_GDRIVE + "photos/IMG_1591718605.png") # Blur
#img = cv.imread(DIR_GDRIVE + "photos/IMG_1591718593.png") # Focus


#img = cv.resize(img, (SIZE, SIZE), interpolation = cv.INTER_AREA)
figure(figsize=(1,1)) 
plt.imshow(img, cmap='gray');

# CROP IMAGE 
x = y = 0
h = w = IMAGE_RESIZE
img_array = []
sub_images = int(img.shape[0] / IMAGE_RESIZE)
print("Número de divisiones en la imagen: ", sub_images**2)

for j in range(sub_images):
  for z in range (sub_images):
    x = IMAGE_RESIZE * z 
    y = IMAGE_RESIZE * j
    img_crop = img[y:y+h, x:x+w]
    img_array.append(img_crop)

showGridImage(img_array)

# ALMACENAMOS LA IMAGEN EN GDRIVE
index=0

for im in img_array:
  path = DIR_GDRIVE + 'imagen/test/' + str(index) + '.png'
  print(path)
  cv.imwrite(path, im)
  index += 1

imageGenerator = ImageDataGenerator()
path = DIR_GDRIVE + 'imagen/'

batch_size = sub_images**2

testGEN = imageGenerator.flow_from_directory(
          directory= path,
          target_size=(IMAGE_RESIZE, IMAGE_RESIZE),
          batch_size=batch_size,
          class_mode=None
      );

# PREDICCION
predictBlur(modelo, img_array)

#keras_model = tf.keras.models.load_model(DIR_GDRIVE + "modelo_32x3pNET")

# Convert model to tensorflowLite

converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)
tf_lite_model = converter.convert()
open(DIR_GDRIVE + "modeloLite_32xpNet", "wb").write(tf_lite_model)